<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="description" content="Go应用优化指北"/>




  <meta name="keywords" content="golang优化," />





  <link rel="alternate" href="/atom.xml" title="RiddleGo" type="application/atom+xml">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=1.1" />



<link rel="canonical" href="https://riddlego.github.io/2021/08/22/Go应用优化指北/"/>


<meta name="description" content="全文来自曹大微信公众号–点击进入原文 真的太建议大家好好阅读一下曹大的文章，我们学生因为没有在工作中接触真正的业务，曹大总能把很厉害的实际的技术讲的很通透。瑞思拜。 为什么要做优化这是一个速度决定一切的时代，我们的生活在不断地数字化，线下的流程依然在持续向线上转移，转移过程中，作为工程师，我们会碰到各种各样的性能问题。 互联网公司本质是将用户共通的行为流程进行了集中化管理，通过中心化的信息交换达到">
<meta property="og:type" content="article">
<meta property="og:title" content="Go应用优化指北">
<meta property="og:url" content="https://riddlego.github.io/2021/08/22/Go%E5%BA%94%E7%94%A8%E4%BC%98%E5%8C%96%E6%8C%87%E5%8C%97/index.html">
<meta property="og:site_name" content="RiddleGo">
<meta property="og:description" content="全文来自曹大微信公众号–点击进入原文 真的太建议大家好好阅读一下曹大的文章，我们学生因为没有在工作中接触真正的业务，曹大总能把很厉害的实际的技术讲的很通透。瑞思拜。 为什么要做优化这是一个速度决定一切的时代，我们的生活在不断地数字化，线下的流程依然在持续向线上转移，转移过程中，作为工程师，我们会碰到各种各样的性能问题。 互联网公司本质是将用户共通的行为流程进行了集中化管理，通过中心化的信息交换达到">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gitee.com/psycho1900/miss-reddle/raw/master/process/%E4%BC%98%E5%8C%9601.png">
<meta property="og:image" content="https://gitee.com/psycho1900/miss-reddle/raw/master/process/%E4%BC%98%E5%8C%9602.png">
<meta property="og:image" content="https://gitee.com/psycho1900/miss-reddle/raw/master/process/%E4%BC%98%E5%8C%9603.png">
<meta property="article:published_time" content="2021-08-22T08:27:52.000Z">
<meta property="article:modified_time" content="2021-08-31T13:49:18.789Z">
<meta property="article:author" content="Russshare">
<meta property="article:tag" content="golang优化">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gitee.com/psycho1900/miss-reddle/raw/master/process/%E4%BC%98%E5%8C%9601.png">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1" />
<link href='https://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet'>





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  



    <title> Go应用优化指北 - RiddleGo </title>
  <meta name="generator" content="Hexo 5.4.0"></head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">RiddleGo</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/archives">
                            
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Go应用优化指北
        
      </h1>

      <time class="post-time">
          8月 22 2021
      </time>
    </header>



    
            <div class="post-content">
            <p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/X7OU9JjSThB5IZF_KVT1Jg">全文来自曹大微信公众号–点击进入原文</a></p>
<p>真的太建议大家好好阅读一下曹大的文章，我们学生因为没有在工作中接触真正的业务，曹大总能把很厉害的实际的技术讲的很通透。瑞思拜。</p>
<h2 id="为什么要做优化"><a href="#为什么要做优化" class="headerlink" title="为什么要做优化"></a>为什么要做优化</h2><p>这是一个速度决定一切的时代，我们的生活在不断地数字化，线下的流程依然在持续向线上转移，转移过程中，作为工程师，我们会碰到各种各样的性能问题。</p>
<p>互联网公司本质是将用户共通的行为流程进行了集中化管理，通过中心化的信息交换达到效率提升的目的，同时用规模效应降低了数据交换的成本。</p>
<p>用人话来讲，公司希望的是用尽量少的机器成本来赚取尽量多的利润。利润的提升与业务逻辑本身相关，与技术关系不大。而降低成本则是与业务无关，纯粹的技术话题。这里面最重要的主题就是“性能优化”。</p>
<p>如果业务的后端服务规模足够大，那么一个程序员通过优化帮公司节省的成本，就可以负担他十年的工资了。</p>
<h2 id="优化的前置知识"><a href="#优化的前置知识" class="headerlink" title="优化的前置知识"></a>优化的前置知识</h2><p>从资源视角出发来对一台服务器进行审视的话，<strong>CPU、内存、磁盘与网络</strong>是后端服务最需要关注的四种资源类型。</p>
<p>对于<strong>计算密集型的程序来说，优化的主要精力会放在 CPU 上，要知道 CPU 基本的流水线概念，知道怎么样在使用少的 CPU 资源的情况下，达到相同的计算目标。</strong></p>
<p>对于 <strong>IO 密集型的程序(后端服务一般都是 IO 密集型)来说，优化可以是降低程序的服务延迟，也可以是提升系统整体的吞吐量。</strong></p>
<p><strong>IO 密集型应用主要与磁盘、内存、网络打交道</strong>。因此我们需要知道一些基本的与磁盘、内存、网络相关的基本数据与常见概念：</p>
<ul>
<li><p>要了解内存的多级存储结构：L1，L2，L3，主存。还要知道这些不同层级的存储操作时的大致延迟：latency numbers every programmer should know[1]。</p>
</li>
<li><p>要知道基本的文件系统读写 syscall，批量 syscall，数据同步 syscall。</p>
</li>
<li><p>要熟悉项目中使用的网络协议，至少要对 TCP, HTTP 有所了解。</p>
</li>
</ul>
<h2 id="优化越靠近应用层效果越好"><a href="#优化越靠近应用层效果越好" class="headerlink" title="优化越靠近应用层效果越好"></a>优化越靠近应用层效果越好</h2><hr>
<p>Performance tuning is most effective when done closest to where the work is performed. For workloads driven by applications, this means within the application itself.</p>
<p>我们在应用层的逻辑优化能够帮助应用提升几十倍的性能，而最底层的优化则只能提升几个百分点。</p>
<p>这个很好理解，我们可以看到一个 GTA Online 的新闻：<strong>rockstar thanks gta online player who fixed poor load times</strong>[2]。</p>
<p>简单来说，GTA online 的游戏启动过程让玩家等待时间过于漫长，经过各种工具分析，发现一个 10M 的文件加载就需要几十秒，用户 diy 进行优化之后，将加载时间减少 70%，并分享出来：how I cut GTA Online loading times by 70%[3]。</p>
<p>这就是一个非常典型的案例，GTA 在商业上取得了巨大的成功，但不妨碍它局部的代码是一坨屎。我们只要把这里的重复逻辑干掉，就可以完成三倍的优化效果。同样的案例，如果我们去优化磁盘的读写速度，则可能收效甚微。</p>
<h2 id="优化是与业务场景相关的"><a href="#优化是与业务场景相关的" class="headerlink" title="优化是与业务场景相关的"></a>优化是与业务场景相关的</h2><p>不同的业务场景优化的侧重也是不同的。</p>
<p><strong>对于大多数无状态业务模块来说，内存一般不是瓶颈，所以业务 API 的优化主要聚焦于延迟和吞吐。<strong><strong>对于网关类的应用，因为有海量的连接，除了延迟和吞吐，内存占用可能就会成为一个关注的重点。</strong></strong>对于存储类应用，内存是个逃不掉的瓶颈点。</strong></p>
<p>在关注一些性能优化文章时，我们也应特别留意作者的业务场景。场景的侧重可能会让某些人去选择使用更为 hack 的手段进行优化，而 hack 往往也就意味着 bug。如果你选择了少有人走过的路，那你要面临的也是少有人会碰到的 bug。解决起来令人头疼。</p>
<h2 id="优化的工作流程"><a href="#优化的工作流程" class="headerlink" title="优化的工作流程"></a>优化的工作流程</h2><p>对于一个典型的 API 应用来说，优化工作基本遵从下面的工作流：</p>
<p>1、建立评估指标，例如固定 QPS 压力下的延迟或内存占用，或模块在满足 SLA 前提下的极限 QPS</p>
<p>2、通过自研、开源压测工具进行压测，直到模块无法满足预设性能要求:如大量超时，QPS 不达预期，OOM</p>
<p>3、通过内置 profile 工具寻找性能瓶颈</p>
<p>4、本地 benchmark 证明优化效果</p>
<p>5、集成 patch 到业务模块，回到 2</p>
<h2 id="可以使用的工具"><a href="#可以使用的工具" class="headerlink" title="可以使用的工具"></a>可以使用的工具</h2><h3 id="pprof"><a href="#pprof" class="headerlink" title="pprof"></a>pprof</h3><h4 id="memory-profiler"><a href="#memory-profiler" class="headerlink" title="memory profiler"></a>memory profiler</h4><p>Go 内置的内存 profiler 可以让我们对线上系统进行内存使用采样，有四个相应的指标：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">inuse_objects：当我们认为内存中的驻留对象过多时，就会关注该指标</span><br><span class="line"></span><br><span class="line">inuse_space：当我们认为应用程序占据的 RSS 过大时，会关注该指标</span><br><span class="line"></span><br><span class="line">alloc_objects：当应用曾经发生过历史上的大量内存分配行为导致 CPU 或内存使用大幅上升时，可能关注该指标</span><br><span class="line"></span><br><span class="line">alloc_space：当应用历史上发生过内存使用大量上升时，会关注该指标</span><br></pre></td></tr></table></figure>

<p><strong>网关类应用因为海量连接的关系，会导致进程消耗大量内存，</strong>所以我们经常看到相关的优化文章，主要就是降低应用的 inuse_space。</p>
<p><strong>而两个对象数指标主要是为 GC 优化提供依据，</strong>当我们进行 GC 调优时，会同时关注<strong>应用分配的对象数、****正在使用的对象数</strong>，<strong>以及 GC 的 CPU 占用的指标。</strong></p>
<p>GC 的 CPU 占用情况可以由内置的 CPU profiler 得到。</p>
<h4 id="cpu-profiler"><a href="#cpu-profiler" class="headerlink" title="cpu profiler"></a>cpu profiler</h4><hr>
<p>The builtin Go CPU profiler uses the setitimer(2) system call to ask the operating system to be sent a SIGPROF signal 100 times a second. Each signal stops the Go process and gets delivered to a random thread’s sigtrampgo() function. This function then proceeds to call sigprof() or sigprofNonGo() to record the thread’s current stack.</p>
<p>Go 语言内置的 CPU profiler 使用 setitimer 系统调用，操作系统会每秒 100 次向程序发送 SIGPROF 信号。在 Go 进程中会选择随机的信号执行 sigtrampgo 函数。该函数使用 sigprof 或 sigprofNonGo 来记录线程当前的栈。</p>
<p>Since Go uses non-blocking I/O, Goroutines that wait on I/O are parked and not running on any threads. Therefore they end up being largely invisible to Go’s builtin CPU profiler.</p>
<p>Go 语言内置的 cpu profiler 是在性能领域比较常见的 On-CPU profiler，对于瓶颈主要在 CPU 消耗的应用，我们使用内置的 profiler 也就足够了。</p>
<p>如果碰到的问题是应用的 CPU 使用不高，但接口的延迟却很大，那么就需要用上 Off-CPU profiler，遗憾的是官方的 profiler 并未提供该功能，我们需要借助社区的 fgprof。</p>
<h4 id="fgprof"><a href="#fgprof" class="headerlink" title="fgprof"></a>fgprof</h4><hr>
<p>gprof is implemented as a background goroutine that wakes up 99 times per second and calls runtime.GoroutineProfile. This returns a list of all goroutines regardless of their current On/Off CPU scheduling status and their call stacks.</p>
<p>fgprof 是启动了一个后台的 goroutine，每秒启动 99 次，调用 runtime.GoroutineProfile 来采集所有 gorooutine 的栈。</p>
<p>虽然看起来很美好：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">func GoroutineProfile(p []StackRecord) (n int, ok bool) &#123;</span><br><span class="line">    .....</span><br><span class="line"> stopTheWorld(&quot;profile&quot;)</span><br><span class="line"></span><br><span class="line"> for _, gp1 :&#x3D; range allgs &#123;</span><br><span class="line">  ......</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> if n &lt;&#x3D; len(p) &#123;</span><br><span class="line">  &#x2F;&#x2F; Save current goroutine.</span><br><span class="line">  ........</span><br><span class="line">  systemstack(func() &#123;</span><br><span class="line">   saveg(pc, sp, gp, &amp;r[0])</span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line">  &#x2F;&#x2F; Save other goroutines.</span><br><span class="line">  for _, gp1 :&#x3D; range allgs &#123;</span><br><span class="line">   if isOK(gp1) &#123;</span><br><span class="line">    .......</span><br><span class="line">    saveg(^uintptr(0), ^uintptr(0), gp1, &amp;r[0])</span><br><span class="line">                .......</span><br><span class="line">   &#125;</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> startTheWorld()</span><br><span class="line"></span><br><span class="line"> return n, ok</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>但调用 GoroutineProfile 函数的开销并不低，如果线上系统的 goroutine 上万，每次采集 profile 都遍历上万个 goroutine 的成本实在是太高了。所以 fgprof 只适合在测试环境中使用。</p>
<h4 id="trace"><a href="#trace" class="headerlink" title="trace"></a>trace</h4><p>一般情况下我们是不需要使用 trace 来定位性能问题的，通过压测 + profile 就可以解决大部分问题，除非我们的问题与 runtime 本身的问题相关。</p>
<p>比如 STW 时间比预想中长，超过百毫秒，向官方反馈问题时，才需要出具相关的 trace 文件。比如类似 long stw[4] 这样的 issue。</p>
<p>采集 trace 对系统的性能影响还是比较大的，即使我们只是开启 gctrace，把 gctrace 日志重定向到文件，对系统延迟也会有一定影响，因为 gctrace 的日志 print 是在 stw 期间来做的：gc trace 阻塞调度[5]。</p>
<h4 id="perf"><a href="#perf" class="headerlink" title="perf"></a>perf</h4><p>如果应用没有开启 pprof，在线上应急时，我们也可以临时使用 perf：</p>
<p><img src="https://gitee.com/psycho1900/miss-reddle/raw/master/process/%E4%BC%98%E5%8C%9601.png"></p>
<h2 id="微观性能优化"><a href="#微观性能优化" class="headerlink" title="微观性能优化"></a>微观性能优化</h2><p>编写 library 时会关注关键函数的性能，这时可以脱离系统去探讨性能优化，Go 语言的 test 子命令集成了相关的功能，<strong>只要我们按照约定来写 Benchmark 前缀的测试函数</strong>，就可以实现函数级的基准测试。我们以常见的二维数组遍历为例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">package main</span><br><span class="line"></span><br><span class="line">import &quot;testing&quot;</span><br><span class="line"></span><br><span class="line">var x &#x3D; make([][]int, 100)</span><br><span class="line"></span><br><span class="line">func init() &#123;</span><br><span class="line"> for i :&#x3D; 0; i &lt; 100; i++ &#123;</span><br><span class="line">  x[i] &#x3D; make([]int, 100)</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func traverseVertical() &#123;</span><br><span class="line"> for i :&#x3D; 0; i &lt; 100; i++ &#123;</span><br><span class="line">  for j :&#x3D; 0; j &lt; 100; j++ &#123;</span><br><span class="line">   x[j][i] &#x3D; 1</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func traverseHorizontal() &#123;</span><br><span class="line"> for i :&#x3D; 0; i &lt; 100; i++ &#123;</span><br><span class="line">  for j :&#x3D; 0; j &lt; 100; j++ &#123;</span><br><span class="line">   x[i][j] &#x3D; 1</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func BenchmarkHorizontal(b *testing.B) &#123;</span><br><span class="line"> for i :&#x3D; 0; i &lt; b.N; i++ &#123;</span><br><span class="line">  traverseHorizontal()</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func BenchmarkVertical(b *testing.B) &#123;</span><br><span class="line"> for i :&#x3D; 0; i &lt; b.N; i++ &#123;</span><br><span class="line">  traverseVertical()</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>执行 go test -bench=.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">BenchmarkHorizontal-12       102368      10916 ns&#x2F;op</span><br><span class="line">BenchmarkVertical-12          66612      18197 ns&#x2F;op</span><br></pre></td></tr></table></figure>
<p><strong>可见横向遍历数组要快得多，这提醒我们在写代码时要考虑 CPU 的 cache 设计及局部性原理，以使程序能够在相同的逻辑下获得更好的性能。</strong></p>
<p>除了 CPU 优化，我们还经常会碰到要优化内存分配的场景。只要带上 -benchmem 的 flag 就可以实现了。</p>
<p>举个例子，形如下面这样的代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logStr :&#x3D; &quot;userid :&quot; + userID + &quot;; orderid:&quot; + orderID</span><br></pre></td></tr></table></figure>
<p>你觉得代码写的很难看，想要优化一下可读性，就改成了下列代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logStr :&#x3D; fmt.Sprintf(&quot;userid: %v; orderid: %v&quot;, userID, orderID)</span><br></pre></td></tr></table></figure>

<p>这样的修改方式在某公司的系统中曾经导致了 p2 事故，上线后接口的超时俱增至 SLA 承诺以上。</p>
<p>我们简单验证就可以发现：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">BenchmarkPrin-12       7168467        157 ns&#x2F;op       64 B&#x2F;op        3 allocs&#x2F;op</span><br><span class="line">BenchmarkPlus -12     43278558         26.7 ns&#x2F;op        0 B&#x2F;op        0 allocs&#x2F;op</span><br></pre></td></tr></table></figure>
<p><strong>使用 + 进行字符串拼接，不会在堆上产生额外对象。****而使用 fmt 系列函数，则会造成局部对象逃逸到堆上，这里是高频路径上有大量逃逸，所以导致线上服务的 GC 压力加重，大量接口超时。</strong></p>
<p>出于谨慎考虑，修改高并发接口时，拿不准的尽量都应进行简单的线下 benchmark 测试。</p>
<p>当然，我们不能指望靠写一大堆 benchmark 帮我们发现系统的瓶颈。</p>
<p><strong>实际工作中还是要使用前文提到的优化工作流来进行系统性能优化。也就是尽量从接口整体而非函数局部考虑去发现与解决瓶颈。</strong></p>
<h2 id="宏观性能优化"><a href="#宏观性能优化" class="headerlink" title="宏观性能优化"></a>宏观性能优化</h2><p>接口类的服务，我们可以使用两种方式对其进行压测：</p>
<ul>
<li><p>固定 QPS 压测：在每次系统有大的特性发布时，都应进行固定 QPS 压测，<strong>与历史版本进行对比，****需要关注的指标包括，相同 QPS 下的系统的 CPU 使用情况，内存占用情况(监控中的 RSS 值)，goroutine 数，GC 触发频率和相关指标(是否有较长的 stw，mark 阶段是否时间较长等)，平均延迟，p99 延迟。</strong></p>
</li>
<li><p>极限 QPS 压测：极限 QPS 压测一般只是为了 benchmark show，没有太大意义。系统满负荷时，基本 p99 已经超出正常用户的忍受范围了。</p>
</li>
</ul>
<p>压测过程中需要采集不同 QPS 下的 CPU profile，内存 profile，记录 goroutine 数。与历史情况进行 AB 对比。</p>
<p>Go 的 pprof 还提供了 –base 的 flag，能够很直观地帮我们发现不同版本之间的指标差异：用 pprof 比较内存使用差异[6]。</p>
<p><strong>总之记住一点，接口的性能一定是通过压测来进行优化的，而不是通过硬啃代码找瓶颈点。****关键路径的简单修改往往可以带来巨大收益。如果只是啃代码，很有可能将 1% 优化到 0%，优化了 100% 的局部性能，对接口整体影响微乎其微。</strong></p>
<h2 id="寻找性能瓶颈"><a href="#寻找性能瓶颈" class="headerlink" title="寻找性能瓶颈"></a>寻找性能瓶颈</h2><p>在压测时，我们通过以下步骤来逐渐提升接口的整体性能：</p>
<ul>
<li><p>使用固定 QPS 压测，以阶梯形式逐渐增加压测 QPS，如 1000 -&gt; 每分钟增加 1000 QPS</p>
</li>
<li><p>压测过程中观察系统的延迟是否异常</p>
</li>
<li><p>观察系统的 CPU 使用情况</p>
</li>
<li><p>如果 CPU 使用率在达到一定值之后不再上升，反而引起了延迟的剧烈波动，这时大概率是发生了阻塞，进入 pprof 的 web 页面，点击 goroutine，查看 top 的 goroutine 数，这时应该有大量的 goroutine 阻塞在某处，比如 Semacquire</p>
</li>
<li><p>如果 CPU 上升较快，未达到预期吞吐就已经过了高水位，则可以重点考察 CPU 使用是否合理，<strong>在 CPU 高水位进行 profile 采样，重点关注火焰图中较宽的“平顶山”</strong></p>
</li>
<li><p>重复上述步骤，直至系统性能达到或超越我们设置的性能目标。</p>
</li>
</ul>
<h2 id="一些优化案例"><a href="#一些优化案例" class="headerlink" title="一些优化案例"></a>一些优化案例</h2><h3 id="gc-mark-占用过多-CPU"><a href="#gc-mark-占用过多-CPU" class="headerlink" title="gc mark 占用过多 CPU"></a>gc mark 占用过多 CPU</h3><p>在 Go 语言中 gc mark 占用的 CPU 主要和运行时的对象数相关，也就是我们需要看 inuse_objects。</p>
<p>定时任务，或访问流量不规律的应用，需要关注 alloc_objects。</p>
<p>优化主要是下面几方面：</p>
<h3 id="减少变量逃逸"><a href="#减少变量逃逸" class="headerlink" title="减少变量逃逸"></a>减少变量逃逸</h3><p><strong>尽量在栈上分配对象，关于逃逸的规则，可以查看</strong> Go 编译器代码中的逃逸测试部分：</p>
<p><img src="https://gitee.com/psycho1900/miss-reddle/raw/master/process/%E4%BC%98%E5%8C%9602.png"></p>
<p>查看某个 package 内的逃逸情况，可以使用 build + 全路径的方式，如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go build -gcflags&#x3D;&quot;-m -m&quot; github.com&#x2F;cch123&#x2F;elasticsql</span><br></pre></td></tr></table></figure>
<p>需要注意的是，逃逸分析的结果是会随着版本变化的，所以去背诵网上逃逸相关的文章结论是没有什么意义的。</p>
<h3 id="使用-sync-Pool-复用堆上对象"><a href="#使用-sync-Pool-复用堆上对象" class="headerlink" title="使用 sync.Pool 复用堆上对象"></a>使用 sync.Pool 复用堆上对象</h3><p>sync.Pool 用出花儿的就是 fasthttp 了，可以看看我之前写的这一篇：fasthttp 为什么快[7]。</p>
<p>最简单的复用就是复用各种 struct，slice，<strong>在复用时 put 时，需要判断 size 是否已经扩容过头，小心因为 sync.Pool 中存了大量的巨型对象导致进程占用了大量内存</strong></p>
<h3 id="调度占用过多-CPU"><a href="#调度占用过多-CPU" class="headerlink" title="调度占用过多 CPU"></a>调度占用过多 CPU</h3><p>goroutine 频繁创建与销毁会给调度造成较大的负担，如果我们发<strong>现 CPU 火焰图中 schedule，findrunnable 占用了大量 CPU，那么可以考虑使用开源的 workerpool 来进行改进，比较典型的 fasthttp worker pool[8]。</strong></p>
<p><strong>如果客户端与服务端之间使用的是短连接，那么我们可以使用长连接来减少连接创建的开销，这里就包含了 goroutine 的创建与销毁。</strong></p>
<h3 id="进程占用大量内存"><a href="#进程占用大量内存" class="headerlink" title="进程占用大量内存"></a>进程占用大量内存</h3><p>当前大多数的业务后端服务是不太需要关注进程消耗的内存的。</p>
<p><strong>我们经常看到做 Go 内存占用优化的是在网关(包括 mesh)、存储系统这两个场景。</strong></p>
<p>对于网关类系统来说，Go 的内存占用主要是因为 Go 独特的抽象模型造成的，这个很好理解：<br><img src="https://gitee.com/psycho1900/miss-reddle/raw/master/process/%E4%BC%98%E5%8C%9603.png"></p>
<p>海量的连接加上海量的 goroutine，使网关和 mesh 成为 Go OOM 的重灾区。所以网关侧的优化一般就是优化：</p>
<ul>
<li><p>goroutine 占用的栈内存</p>
</li>
<li><p>read buffer 和 write buffer 占用的内存</p>
</li>
</ul>
<p>很多项目都有相关的分享，这里就不再赘述了。</p>
<p><strong>对于存储类系统来说，内存占用方面的不少努力也是在优化各种 buffer</strong>，比如 dgraph 使用 cgo + jemalloc 来优化他们的产品内存占用[9]。</p>
<p>堆外内存不会在 Go 的 GC 系统里进行管辖，所以也不会影响到 Go 的 GC Heap Goal，所以不会因为分配大量对象造成 Go 的 Heap Goal 被推高，系统整体占用的 RSS 也被推高。</p>
<h3 id="锁冲突严重，导致吞吐量瓶颈"><a href="#锁冲突严重，导致吞吐量瓶颈" class="headerlink" title="锁冲突严重，导致吞吐量瓶颈"></a>锁冲突严重，导致吞吐量瓶颈</h3><p>我在 几个 Go 系统可能遇到的锁问题[10] 中分享过实际的线上 case。</p>
<p><strong>进行锁优化的思路无非就一个“拆”和一个“缩”字：</strong></p>
<ul>
<li><p>拆：将锁粒度进行拆分，<strong>比如全局锁，我能不能把锁粒度拆分为连接粒度的锁</strong>；<strong>如果是连接粒度的锁，那我能不能拆分为请求粒度的锁</strong>；在 logger fd 或 net fd 上加的锁不太好拆，那么我们增加一些客户端，比如从 1-&gt; 100，降低锁的冲突是不是就可以了。</p>
</li>
<li><p>缩：<strong>缩小锁的临界区，业务允许的前提下，可以把 syscall 移到锁外面</strong>；<strong>有时只是想要锁 map 的读写逻辑，但是却不小心锁了连接读写的逻辑，或许简单地用 sync.Map 来代替 map Lock</strong>，defer Unlock 就能简单地缩小临界区了。</p>
</li>
</ul>
<h3 id="timer-相关函数占用大量-CPU"><a href="#timer-相关函数占用大量-CPU" class="headerlink" title="timer 相关函数占用大量 CPU"></a>timer 相关函数占用大量 CPU</h3><p>同样是在网关和海量连接的应用中较常见，优化手段：</p>
<ul>
<li><p>使用时间轮/粗粒度的时间管理，精确到 ms 级一般就足够了</p>
</li>
<li><p>升级到 Go 1.14+，享受官方的升级红利</p>
</li>
</ul>
<h2 id="模拟真实工作负载"><a href="#模拟真实工作负载" class="headerlink" title="模拟真实工作负载"></a>模拟真实工作负载</h2><p>在前面的论述中，我们对问题进行了简化。真实世界中的后端系统往往不只一个接口，压测工具、平台往往只支持单接口压测。</p>
<p>公司的业务希望知道的是后端系统整体性能，即这些系统作为一个整体，在限定的资源条件下，能够承载多少业务量(如并发创建订单)而不崩溃。</p>
<p>虽然大家都在讲微服务，但单一服务往往也不只有单一功能，如果一个系统有 10 个接口(已经算是很小的服务了)，那么这个服务的真实负载是很难靠人肉去模拟的。</p>
<p>这也就是为什么互联网公司普遍都需要<strong>做全链路压测。</strong>像样点的公司会定期进行全链路压测演练，以便知晓随着系统快速迭代变化，系统整体是否出现了严重的性能衰退。</p>
<p>通过真实的工作负载，我们才能发现真实的线上性能问题。讲全链路压测的文章也很多，本文就不再赘述了。</p>
<h2 id="当前性能问题定位工具的局限性"><a href="#当前性能问题定位工具的局限性" class="headerlink" title="当前性能问题定位工具的局限性"></a>当前性能问题定位工具的局限性</h2><p>本文中几乎所有优化手段都是通过 Benchmark 和压测来进行的，但真实世界的软件还会有下列场景：</p>
<ul>
<li>做 ToB 生意，我们的应用是部署在客户侧(比如一些数据库产品)，客户说我们的应用会 OOM，但是我们很难拿到 OOM 的现场，不知道到底是哪些对象分配导致了 OOM</li>
</ul>
<p>(toB即面向企业， toC即面向普通用户)</p>
<ul>
<li>做大型平台，平台上有各种不同类型的用户编写代码，升级用户代码后，线上出现各种 CPU 毛刺和 OOM 问题</li>
</ul>
<p>这些问题在压测中是发现不了的，需要有更为灵活的工具和更为强大的平台，关于这些问题，我将在 4 月 10 日的武汉 Gopher Meetup 上进行分享，欢迎关注。</p>
<p>推荐阅读：cache contention[11]</p>
<p>every-programmer-should-know[12]</p>
<p>go-perfbook[13]</p>
<p>Systems Performance[14]</p>
<p>[1]<br>latency numbers every programmer should know: <a target="_blank" rel="noopener" href="https://colin-scott.github.io/personal_website/research/interactive_latency.html">https://colin-scott.github.io/personal_website/research/interactive_latency.html</a></p>
<p>[2]<br>rockstar thanks gta online player who fixed poor load times: <a target="_blank" rel="noopener" href="https://www.pcgamer.com/rockstar-thanks-gta-online-player-who-fixed-poor-load-times-official-update-coming/">https://www.pcgamer.com/rockstar-thanks-gta-online-player-who-fixed-poor-load-times-official-update-coming/</a></p>
<p>[3]<br>how I cut GTA Online loading times by 70%: <a target="_blank" rel="noopener" href="https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/">https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/</a></p>
<p>[4]<br>long stw: <a target="_blank" rel="noopener" href="https://github.com/golang/go/issues/19378">https://github.com/golang/go/issues/19378</a></p>
<p>[5]<br>gc trace 阻塞调度: <a target="_blank" rel="noopener" href="http://xiaorui.cc/archives/6232">http://xiaorui.cc/archives/6232</a></p>
<p>[6]<br>用 pprof 比较内存使用差异: <a target="_blank" rel="noopener" href="https://colobu.com/2019/08/20/use-pprof-to-compare-go-memory-usage/">https://colobu.com/2019/08/20/use-pprof-to-compare-go-memory-usage/</a></p>
<p>[7]<br>fasthttp 为什么快: <a target="_blank" rel="noopener" href="https://xargin.com/why-fasthttp-is-fast-and-the-cost-of-it/">https://xargin.com/why-fasthttp-is-fast-and-the-cost-of-it/</a></p>
<p>[8]<br>fasthttp worker pool: <a target="_blank" rel="noopener" href="https://github.com/valyala/fasthttp/blob/master/workerpool.go#L19">https://github.com/valyala/fasthttp/blob/master/workerpool.go#L19</a></p>
<p>[9]<br>内存占用: <a target="_blank" rel="noopener" href="https://dgraph.io/blog/post/manual-memory-management-golang-jemalloc/">https://dgraph.io/blog/post/manual-memory-management-golang-jemalloc/</a></p>
<p>[10]<br>几个 Go 系统可能遇到的锁问题: <a target="_blank" rel="noopener" href="https://xargin.com/lock-contention-in-go/">https://xargin.com/lock-contention-in-go/</a></p>
<p>[11]<br>cache contention: <a target="_blank" rel="noopener" href="https://web.eecs.umich.edu/~zmao/Papers/xu10mar.pdf">https://web.eecs.umich.edu/~zmao/Papers/xu10mar.pdf</a></p>
<p>[12]<br>every-programmer-should-know: <a target="_blank" rel="noopener" href="https://github.com/mtdvio/every-programmer-should-know">https://github.com/mtdvio/every-programmer-should-know</a></p>
<p>[13]<br>go-perfbook: <a target="_blank" rel="noopener" href="https://github.com/dgryski/go-perfbook">https://github.com/dgryski/go-perfbook</a></p>
<p>[14]<br>Systems Performance: <a target="_blank" rel="noopener" href="https://www.amazon.com/Systems-Performance-Brendan-Gregg/dp/0136820158/ref=sr_1_1?dchild=1&amp;keywords=systems+performance&amp;qid=1617092159&amp;sr=8-1">https://www.amazon.com/Systems-Performance-Brendan-Gregg/dp/0136820158/ref=sr_1_1?dchild=1&amp;keywords=systems+performance&amp;qid=1617092159&amp;sr=8-1</a></p>

            </div>
          

    
      <footer class="post-footer">
		
		<div class="post-tags">
		  
			<a href="/tags/golang%E4%BC%98%E5%8C%96/">golang优化</a>
		  
		</div>
		

        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2021/08/22/runtime%E5%8C%85/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">runtime包</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2021/08/22/sync%E5%8C%85%EF%BC%88%E4%B8%8B%E9%9B%A8%E5%A4%A9%E7%AA%81%E7%84%B6%E6%83%B3%E8%B5%B7%E7%9A%84%E4%B8%80%E4%B8%AA%E7%9F%A5%E8%AF%86%E7%82%B9%EF%BC%89/">
        <span class="next-text nav-default">sync包（下雨天突然想起的一个知识点）</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2014 -
    
    2021
    <span class="footer-author">Russshare.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> and <a class="theme-link" target="_blank" rel="noopener" href="https://github.com/frostfan/hexo-theme-polarbear">Polar Bear</a>
    </span>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

  </body>
</html>
